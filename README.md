Tech Stack

Frontend: React (Create React App, TypeScript)
Backend: Node.js, TypeScript, Express
Database: SQLite (via Prisma ORM)
LLM: Google Gemini (via @google/genai)
Other: Prisma, dotenv


üõ†Ô∏è How to Run Locally (Step by Step)
1Ô∏è‚É£ Prerequisites
Node.js v20 LTS(imp)
npm
----------------------------------------------------------------------

2Ô∏è‚É£ Clone the repository
git clone <your-repo-url>
cd spur
----------------------------------------------------------------------

3Ô∏è‚É£ Backend Setup
cd backend
npm install
----------------------------------------------------------------------

4Ô∏è‚É£ Configure Environment Variables

Create a .env file in backend/ using the example:
cp .env.example .env
Update .env:
GEMINI_API_KEY=your_google_gemini_api_key
.env is ignored via .gitignore and never committed.

----------------------------------------------------------------------

5Ô∏è‚É£ Database Setup (Prisma)

Run migrations:

npm run prisma:generate
npm run prisma:migrate -- --name init


This will:

Create a local SQLite database

Create Conversation and Message tables

----------------------------------------------------------------------


6Ô∏è‚É£ Start Backend Server
npm run dev


Backend runs at:

http://localhost:3001

----------------------------------------------------------------------


7Ô∏è‚É£ Frontend Setup
cd ../react-ui
npm install
npm start


Frontend runs at:

http://localhost:3000

----------------------------------------------------------------------


üí¨ How the App Works

User opens the chat UI

User sends a message

Frontend calls POST /chat/message

Backend:

Creates or validates a conversation

Persists user and AI messages

Calls the LLM with conversation context

AI response is returned and shown in the UI

----------------------------------------------------------------------


üß± Architecture Overview
Backend Structure

Routes
    Handle HTTP requests and responses

Services

    Core business logic
    Conversation lifecycle
    LLM integration

Database (Prisma)

    Conversations and messages persistence

This separation makes it easy to:

    Add new channels (WhatsApp, Instagram, Live Chat)
    Swap LLM providers
    Support human handoff in the future

----------------------------------------------------------------------


üß† LLM Integration

Provider - Google Gemini

SDK - @google/genai

Model Used -gemini-2.5-flash

Prompting Strategy

    A system-style prompt defines the AI as a helpful e-commerce support agent
    Store policies (shipping, returns, support hours) are included
    Recent conversation history is passed on each request to maintain context

----------------------------------------------------------------------


‚ö†Ô∏è Error Handling & Robustness

    Empty or invalid messages are rejected
    LLM/API failures are caught on the backend
    Friendly error messages are returned
    UI displays clean fallback messages without crashing

----------------------------------------------------------------------


üîê Environment & Security

    .env is excluded from git
    .env.example is committed
    No secrets are exposed in the repository

----------------------------------------------------------------------


üîÅ Trade-offs & Design Decisions

    SQLite used for simplicity and fast local setup -(Postgres would be used in production)
    Session-based conversations instead of authentication
    No UI persistence on reload :
        Backend persistence is the primary focus per spec
        UI-side persistence can be added easily if needed

----------------------------------------------------------------------


‚è≥ If I Had More Time‚Ä¶

    Restore chat history on page reload
    Stream LLM responses
    Add retries and timeouts for LLM calls
    Redis caching for sessions
    Human agent handoff
    Analytics and conversation insights
    Production-ready Postgres setup

----------------------------------------------------------------------


‚úÖ Status

    End-to-end chat works
    Conversations are persisted
    Real LLM integration
    Clean, extensible architecture

----------------------------------------------------------------------

